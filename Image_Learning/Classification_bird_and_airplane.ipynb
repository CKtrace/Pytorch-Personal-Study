{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e90fda67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x24d0bdd0770>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "torch.set_printoptions(edgeitems=2, linewidth=75)\n",
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762ec44f",
   "metadata": {},
   "source": [
    "## Preparing Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a71a532",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \".\\\\CIFAR10\\\\\"\n",
    "\n",
    "cifar10 = datasets.CIFAR10(\n",
    "    data_path, train = True, download = False, \n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))\n",
    "    ]))\n",
    "\n",
    "cifar10_val = datasets.CIFAR10(\n",
    "    data_path, train=False, download=False,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4915, 0.4823, 0.4468),(0.2470, 0.2435, 0.2616))\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a012a97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {0: 0, 2: 1}\n",
    "class_names = ['airplane', 'bird']\n",
    "\n",
    "cifar2 = [(img, label_map[label])\n",
    "          for img, label in cifar10 \n",
    "          if label in [0, 2]]\n",
    "\n",
    "cifar2_val = [(img, label_map[label])\n",
    "              for img, label in cifar10_val\n",
    "              if label in [0, 2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214b4df9",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eff188d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb158e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_out = 2\n",
    "\n",
    "model = nn.Sequential(\n",
    "            nn.Linear(3072, 512),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512, n_out),\n",
    "            nn.LogSoftmax(dim = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3a25145",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2ac93a30ee0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, _ = cifar2[0]\n",
    "\n",
    "plt.imshow(img.permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bf117c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.6143, -0.3224,  ..., -1.3170, -1.0472]]), torch.Size([1, 3072]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_batch = img.view(-1).unsqueeze(0)\n",
    "img_batch, img_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "687185e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9942, -0.4621]], grad_fn=<LogSoftmaxBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = model(img_batch)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f17b0261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, index = torch.max(out, dim=1)\n",
    "\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15602a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0472b95b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4621, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img, label = cifar2[0]\n",
    "\n",
    "out = model(img.view(-1).unsqueeze(0))\n",
    "\n",
    "loss(out, torch.tensor([label]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c34ad9",
   "metadata": {},
   "source": [
    "## Classifier Learning -> Using ALL Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb62ba7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Loss: 6.284517765045166\n",
      "Epoch: 1 Loss: 5.426993370056152\n",
      "Epoch: 2 Loss: 8.073309898376465\n",
      "Epoch: 3 Loss: 4.434668064117432\n",
      "Epoch: 4 Loss: 8.861948013305664\n",
      "Epoch: 5 Loss: 9.270270347595215\n",
      "Epoch: 6 Loss: 3.494992256164551\n",
      "Epoch: 7 Loss: 10.184905052185059\n",
      "Epoch: 8 Loss: 5.14982271194458\n",
      "Epoch: 9 Loss: 6.442326068878174\n",
      "Epoch: 10 Loss: 4.864918231964111\n",
      "Epoch: 11 Loss: 0.4014187455177307\n",
      "Epoch: 12 Loss: 5.905603408813477\n",
      "Epoch: 13 Loss: 9.196324348449707\n",
      "Epoch: 14 Loss: 6.336201190948486\n",
      "Epoch: 15 Loss: 7.3022918701171875\n",
      "Epoch: 16 Loss: 1.2945443391799927\n",
      "Epoch: 17 Loss: 2.1799919605255127\n",
      "Epoch: 18 Loss: 2.185661792755127\n",
      "Epoch: 19 Loss: 6.984148025512695\n",
      "Epoch: 20 Loss: 6.187165260314941\n",
      "Epoch: 21 Loss: 10.507281303405762\n",
      "Epoch: 22 Loss: 15.746715545654297\n",
      "Epoch: 23 Loss: 7.049489974975586\n",
      "Epoch: 24 Loss: 8.473156929016113\n",
      "Epoch: 25 Loss: 9.45479965209961\n",
      "Epoch: 26 Loss: 13.265739440917969\n",
      "Epoch: 27 Loss: 10.392166137695312\n",
      "Epoch: 28 Loss: 0.5355349183082581\n",
      "Epoch: 29 Loss: 6.6704583168029785\n",
      "Epoch: 30 Loss: 6.066096782684326\n",
      "Epoch: 31 Loss: 18.17230224609375\n",
      "Epoch: 32 Loss: 0.1610712707042694\n",
      "Epoch: 33 Loss: 8.477615356445312\n",
      "Epoch: 34 Loss: 0.0840744823217392\n",
      "Epoch: 35 Loss: 10.338314056396484\n",
      "Epoch: 36 Loss: 1.7773380279541016\n",
      "Epoch: 37 Loss: 4.734446048736572\n",
      "Epoch: 38 Loss: 0.007600556127727032\n",
      "Epoch: 39 Loss: 3.6702353954315186\n",
      "Epoch: 40 Loss: 0.0003195490571670234\n",
      "Epoch: 41 Loss: 7.906904697418213\n",
      "Epoch: 42 Loss: 0.28188201785087585\n",
      "Epoch: 43 Loss: 9.94827651977539\n",
      "Epoch: 44 Loss: 8.227066040039062\n",
      "Epoch: 45 Loss: 3.9318106174468994\n",
      "Epoch: 46 Loss: 2.6863059997558594\n",
      "Epoch: 47 Loss: 1.5486133098602295\n",
      "Epoch: 48 Loss: 0.8398675322532654\n",
      "Epoch: 49 Loss: 3.167318344116211\n",
      "Epoch: 50 Loss: 6.687758922576904\n",
      "Epoch: 51 Loss: 4.619699478149414\n",
      "Epoch: 52 Loss: 0.08381316810846329\n",
      "Epoch: 53 Loss: 2.9780049324035645\n",
      "Epoch: 54 Loss: 1.4196033477783203\n",
      "Epoch: 55 Loss: 1.5054340362548828\n",
      "Epoch: 56 Loss: 4.302332401275635\n",
      "Epoch: 57 Loss: 9.041437149047852\n",
      "Epoch: 58 Loss: 13.956206321716309\n",
      "Epoch: 59 Loss: 4.446883201599121\n",
      "Epoch: 60 Loss: 9.004181861877441\n",
      "Epoch: 61 Loss: 6.619685173034668\n",
      "Epoch: 62 Loss: 0.31676986813545227\n",
      "Epoch: 63 Loss: 18.76221466064453\n",
      "Epoch: 64 Loss: 11.857307434082031\n",
      "Epoch: 65 Loss: 16.70596694946289\n",
      "Epoch: 66 Loss: 6.469923973083496\n",
      "Epoch: 67 Loss: 4.974926471710205\n",
      "Epoch: 68 Loss: 10.39442253112793\n",
      "Epoch: 69 Loss: 1.7354635000228882\n",
      "Epoch: 70 Loss: 11.150436401367188\n",
      "Epoch: 71 Loss: 9.522067070007324\n",
      "Epoch: 72 Loss: 0.036708053201436996\n",
      "Epoch: 73 Loss: 0.1542346328496933\n",
      "Epoch: 74 Loss: 11.817764282226562\n",
      "Epoch: 75 Loss: 5.9024577140808105\n",
      "Epoch: 76 Loss: 9.707818984985352\n",
      "Epoch: 77 Loss: 8.453751564025879\n",
      "Epoch: 78 Loss: 3.65781569480896\n",
      "Epoch: 79 Loss: 10.078779220581055\n",
      "Epoch: 80 Loss: 8.076541900634766\n",
      "Epoch: 81 Loss: 0.4295106530189514\n",
      "Epoch: 82 Loss: 2.228295087814331\n",
      "Epoch: 83 Loss: 0.04393824189901352\n",
      "Epoch: 84 Loss: 6.6794939041137695\n",
      "Epoch: 85 Loss: 3.5110151767730713\n",
      "Epoch: 86 Loss: 5.560592174530029\n",
      "Epoch: 87 Loss: 11.307347297668457\n",
      "Epoch: 88 Loss: 0.6798959374427795\n",
      "Epoch: 89 Loss: 15.663034439086914\n",
      "Epoch: 90 Loss: 16.339675903320312\n",
      "Epoch: 91 Loss: 8.644230842590332\n",
      "Epoch: 92 Loss: 6.066412448883057\n",
      "Epoch: 93 Loss: 4.6518683433532715\n",
      "Epoch: 94 Loss: 13.063394546508789\n",
      "Epoch: 95 Loss: 6.445634841918945\n",
      "Epoch: 96 Loss: 14.706233024597168\n",
      "Epoch: 97 Loss: 11.059097290039062\n",
      "Epoch: 98 Loss: 14.497553825378418\n",
      "Epoch: 99 Loss: 7.7964582443237305\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "\n",
    "model = nn.Sequential(\n",
    "            nn.Linear(3072, 512),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512, 2),\n",
    "            nn.LogSoftmax(dim = 1))\n",
    "\n",
    "learning_rate = 1e-2\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr = learning_rate)\n",
    "loss_fn = nn.NLLLoss()\n",
    "\n",
    "n_epochs = 100\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for img, label in cifar2:\n",
    "        out = model(img.view(-1).unsqueeze(0))\n",
    "        loss = loss_fn(out, torch.tensor([label]))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f\"Epoch: {epoch} Loss: {float(loss)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c9efc9",
   "metadata": {},
   "source": [
    "## Mini Batch Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8574f56b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Loss: 0.4508588910102844\n",
      "Epoch: 1 Loss: 0.40345385670661926\n",
      "Epoch: 2 Loss: 0.4343932271003723\n",
      "Epoch: 3 Loss: 0.22966347634792328\n",
      "Epoch: 4 Loss: 0.43694308400154114\n",
      "Epoch: 5 Loss: 0.5319609642028809\n",
      "Epoch: 6 Loss: 0.6383283138275146\n",
      "Epoch: 7 Loss: 0.3932562470436096\n",
      "Epoch: 8 Loss: 0.3403806686401367\n",
      "Epoch: 9 Loss: 0.22322754561901093\n",
      "Epoch: 10 Loss: 0.3455077111721039\n",
      "Epoch: 11 Loss: 0.2935001254081726\n",
      "Epoch: 12 Loss: 0.45567044615745544\n",
      "Epoch: 13 Loss: 0.18465575575828552\n",
      "Epoch: 14 Loss: 0.399518221616745\n",
      "Epoch: 15 Loss: 0.5175514817237854\n",
      "Epoch: 16 Loss: 0.27199164032936096\n",
      "Epoch: 17 Loss: 0.14636452496051788\n",
      "Epoch: 18 Loss: 0.40385276079177856\n",
      "Epoch: 19 Loss: 0.37309834361076355\n",
      "Epoch: 20 Loss: 0.4195271134376526\n",
      "Epoch: 21 Loss: 0.5049251317977905\n",
      "Epoch: 22 Loss: 0.18410471081733704\n",
      "Epoch: 23 Loss: 0.3038555681705475\n",
      "Epoch: 24 Loss: 0.30665141344070435\n",
      "Epoch: 25 Loss: 0.48862800002098083\n",
      "Epoch: 26 Loss: 0.1370086967945099\n",
      "Epoch: 27 Loss: 0.23324072360992432\n",
      "Epoch: 28 Loss: 0.2573772072792053\n",
      "Epoch: 29 Loss: 0.4344337284564972\n",
      "Epoch: 30 Loss: 0.15939010679721832\n",
      "Epoch: 31 Loss: 0.17946624755859375\n",
      "Epoch: 32 Loss: 0.12080550193786621\n",
      "Epoch: 33 Loss: 0.1948184370994568\n",
      "Epoch: 34 Loss: 0.15837708115577698\n",
      "Epoch: 35 Loss: 0.11038468778133392\n",
      "Epoch: 36 Loss: 0.11853765696287155\n",
      "Epoch: 37 Loss: 0.12591668963432312\n",
      "Epoch: 38 Loss: 0.07145991176366806\n",
      "Epoch: 39 Loss: 0.12234389036893845\n",
      "Epoch: 40 Loss: 0.1221659928560257\n",
      "Epoch: 41 Loss: 0.12515421211719513\n",
      "Epoch: 42 Loss: 0.15025202929973602\n",
      "Epoch: 43 Loss: 0.12615753710269928\n",
      "Epoch: 44 Loss: 0.03434385359287262\n",
      "Epoch: 45 Loss: 0.37068477272987366\n",
      "Epoch: 46 Loss: 0.03123166784644127\n",
      "Epoch: 47 Loss: 0.16984228789806366\n",
      "Epoch: 48 Loss: 0.010337255895137787\n",
      "Epoch: 49 Loss: 0.020896580070257187\n",
      "Epoch: 50 Loss: 0.21953533589839935\n",
      "Epoch: 51 Loss: 0.06886738538742065\n",
      "Epoch: 52 Loss: 0.04984911531209946\n",
      "Epoch: 53 Loss: 0.1003485843539238\n",
      "Epoch: 54 Loss: 0.04337090253829956\n",
      "Epoch: 55 Loss: 0.04577309265732765\n",
      "Epoch: 56 Loss: 0.06642348319292068\n",
      "Epoch: 57 Loss: 0.14731718599796295\n",
      "Epoch: 58 Loss: 0.08196306228637695\n",
      "Epoch: 59 Loss: 0.037739623337984085\n",
      "Epoch: 60 Loss: 0.048213232308626175\n",
      "Epoch: 61 Loss: 0.02873287908732891\n",
      "Epoch: 62 Loss: 0.029272640123963356\n",
      "Epoch: 63 Loss: 0.03771286830306053\n",
      "Epoch: 64 Loss: 0.0458102747797966\n",
      "Epoch: 65 Loss: 0.022738385945558548\n",
      "Epoch: 66 Loss: 0.06102587655186653\n",
      "Epoch: 67 Loss: 0.03305637091398239\n",
      "Epoch: 68 Loss: 0.049786511808633804\n",
      "Epoch: 69 Loss: 0.03491807356476784\n",
      "Epoch: 70 Loss: 0.022064194083213806\n",
      "Epoch: 71 Loss: 0.02302807942032814\n",
      "Epoch: 72 Loss: 0.03562856838107109\n",
      "Epoch: 73 Loss: 0.01654799096286297\n",
      "Epoch: 74 Loss: 0.013426754623651505\n",
      "Epoch: 75 Loss: 0.03508026525378227\n",
      "Epoch: 76 Loss: 0.015702564269304276\n",
      "Epoch: 77 Loss: 0.06042099744081497\n",
      "Epoch: 78 Loss: 0.052081964910030365\n",
      "Epoch: 79 Loss: 0.016537997871637344\n",
      "Epoch: 80 Loss: 0.011045463383197784\n",
      "Epoch: 81 Loss: 0.01714700646698475\n",
      "Epoch: 82 Loss: 0.015040012076497078\n",
      "Epoch: 83 Loss: 0.009443093091249466\n",
      "Epoch: 84 Loss: 0.0063926056027412415\n",
      "Epoch: 85 Loss: 0.013278341852128506\n",
      "Epoch: 86 Loss: 0.030500533059239388\n",
      "Epoch: 87 Loss: 0.02128320187330246\n",
      "Epoch: 88 Loss: 0.007978863082826138\n",
      "Epoch: 89 Loss: 0.021484456956386566\n",
      "Epoch: 90 Loss: 0.00924055278301239\n",
      "Epoch: 91 Loss: 0.013928238302469254\n",
      "Epoch: 92 Loss: 0.012482333928346634\n",
      "Epoch: 93 Loss: 0.008406712673604488\n",
      "Epoch: 94 Loss: 0.01030693855136633\n",
      "Epoch: 95 Loss: 0.018915025517344475\n",
      "Epoch: 96 Loss: 0.12496229261159897\n",
      "Epoch: 97 Loss: 0.00948491320014\n",
      "Epoch: 98 Loss: 0.012699460610747337\n",
      "Epoch: 99 Loss: 0.013059981167316437\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size = 64, shuffle = True)    # (64, 3, 32, 32)\n",
    "\n",
    "model = nn.Sequential(\n",
    "            nn.Linear(3072, 512),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512, 2),\n",
    "            nn.LogSoftmax(dim = 1))\n",
    "\n",
    "learning_rate = 1e-2\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr = learning_rate)\n",
    "\n",
    "loss_fn = nn.NLLLoss()\n",
    "\n",
    "n_epochs = 100\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for imgs, labels in train_loader:\n",
    "        batch_size = imgs.shape[0]\n",
    "        outputs = model(imgs.view(batch_size, -1))\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "                       \n",
    "    print(f\"Epoch: {epoch} Loss: {float(loss)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e49aeb33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.8215\n"
     ]
    }
   ],
   "source": [
    "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size = 64, shuffle = True)    # (64, 3, 32, 32)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in val_loader:\n",
    "        batch_size = imgs.shape[0]\n",
    "        outputs = model(imgs.view(batch_size, -1))\n",
    "        \n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "        total += labels.shape[0]\n",
    "        correct += int((predicted == labels).sum())\n",
    "\n",
    "print(f\"Accuracy : {float(correct / total)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbfbad3",
   "metadata": {},
   "source": [
    "## Model Parameter Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0421734d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1574402, [1572864, 512, 1024, 2])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numel_list = [p.numel() for p in model.parameters() if p.requires_grad == True]\n",
    "sum(numel_list), numel_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "89d2f7e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1024, 3072]), torch.Size([1024]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear = nn.Linear(3072, 1024)\n",
    "linear.weight.shape, linear.bias.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89f2c52",
   "metadata": {},
   "source": [
    "## Increase Mini Batch Size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ec2ce4a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x0000024D2AE3F400>\n",
      "Epoch: 0 Loss: 0.44410067796707153\n",
      "Epoch: 1 Loss: 0.5403022766113281\n",
      "Epoch: 2 Loss: 0.4614195227622986\n",
      "Epoch: 3 Loss: 0.4297323524951935\n",
      "Epoch: 4 Loss: 0.5954849720001221\n",
      "Epoch: 5 Loss: 0.30401524901390076\n",
      "Epoch: 6 Loss: 0.5017366409301758\n",
      "Epoch: 7 Loss: 0.30500882863998413\n",
      "Epoch: 8 Loss: 0.2971315383911133\n",
      "Epoch: 9 Loss: 0.38058894872665405\n",
      "Epoch: 10 Loss: 0.24604953825473785\n",
      "Epoch: 11 Loss: 0.29362723231315613\n",
      "Epoch: 12 Loss: 0.20171567797660828\n",
      "Epoch: 13 Loss: 0.39221078157424927\n",
      "Epoch: 14 Loss: 0.2017107754945755\n",
      "Epoch: 15 Loss: 0.46517279744148254\n",
      "Epoch: 16 Loss: 0.4052429497241974\n",
      "Epoch: 17 Loss: 0.2602967917919159\n",
      "Epoch: 18 Loss: 0.40013521909713745\n",
      "Epoch: 19 Loss: 0.5454908013343811\n",
      "Epoch: 20 Loss: 0.41754618287086487\n",
      "Epoch: 21 Loss: 0.348655641078949\n",
      "Epoch: 22 Loss: 0.4761049449443817\n",
      "Epoch: 23 Loss: 0.42005205154418945\n",
      "Epoch: 24 Loss: 0.2798437774181366\n",
      "Epoch: 25 Loss: 0.3007623851299286\n",
      "Epoch: 26 Loss: 0.3942333459854126\n",
      "Epoch: 27 Loss: 0.24551281332969666\n",
      "Epoch: 28 Loss: 0.23587369918823242\n",
      "Epoch: 29 Loss: 0.23964495956897736\n",
      "Epoch: 30 Loss: 0.3320865035057068\n",
      "Epoch: 31 Loss: 0.34282514452934265\n",
      "Epoch: 32 Loss: 0.08625655621290207\n",
      "Epoch: 33 Loss: 0.1641676425933838\n",
      "Epoch: 34 Loss: 0.35091572999954224\n",
      "Epoch: 35 Loss: 0.19795441627502441\n",
      "Epoch: 36 Loss: 0.2399805188179016\n",
      "Epoch: 37 Loss: 0.21422523260116577\n",
      "Epoch: 38 Loss: 0.572525143623352\n",
      "Epoch: 39 Loss: 0.24240554869174957\n",
      "Epoch: 40 Loss: 0.17199695110321045\n",
      "Epoch: 41 Loss: 0.27039608359336853\n",
      "Epoch: 42 Loss: 0.11444275081157684\n",
      "Epoch: 43 Loss: 0.25902533531188965\n",
      "Epoch: 44 Loss: 0.2499353587627411\n",
      "Epoch: 45 Loss: 0.09168779850006104\n",
      "Epoch: 46 Loss: 0.2573905289173126\n",
      "Epoch: 47 Loss: 0.42416495084762573\n",
      "Epoch: 48 Loss: 0.09292599558830261\n",
      "Epoch: 49 Loss: 0.1702364832162857\n",
      "Epoch: 50 Loss: 0.36337870359420776\n",
      "Epoch: 51 Loss: 0.06055239588022232\n",
      "Epoch: 52 Loss: 0.2641196548938751\n",
      "Epoch: 53 Loss: 0.07911539077758789\n",
      "Epoch: 54 Loss: 0.07810648530721664\n",
      "Epoch: 55 Loss: 0.08469795435667038\n",
      "Epoch: 56 Loss: 0.2880586087703705\n",
      "Epoch: 57 Loss: 0.09089527279138565\n",
      "Epoch: 58 Loss: 0.41571688652038574\n",
      "Epoch: 59 Loss: 0.12731251120567322\n",
      "Epoch: 60 Loss: 0.11694538593292236\n",
      "Epoch: 61 Loss: 0.2148365080356598\n",
      "Epoch: 62 Loss: 0.34338048100471497\n",
      "Epoch: 63 Loss: 0.28902480006217957\n",
      "Epoch: 64 Loss: 0.31212717294692993\n",
      "Epoch: 65 Loss: 0.2973043918609619\n",
      "Epoch: 66 Loss: 0.1401289701461792\n",
      "Epoch: 67 Loss: 0.17782363295555115\n",
      "Epoch: 68 Loss: 0.13931432366371155\n",
      "Epoch: 69 Loss: 0.16233408451080322\n",
      "Epoch: 70 Loss: 0.1597735732793808\n",
      "Epoch: 71 Loss: 0.1958921253681183\n",
      "Epoch: 72 Loss: 0.13445232808589935\n",
      "Epoch: 73 Loss: 0.13958291709423065\n",
      "Epoch: 74 Loss: 0.09195858240127563\n",
      "Epoch: 75 Loss: 0.07699219882488251\n",
      "Epoch: 76 Loss: 0.08023550361394882\n",
      "Epoch: 77 Loss: 0.051008351147174835\n",
      "Epoch: 78 Loss: 0.20186862349510193\n",
      "Epoch: 79 Loss: 0.04758213087916374\n",
      "Epoch: 80 Loss: 0.024406801909208298\n",
      "Epoch: 81 Loss: 0.06787706911563873\n",
      "Epoch: 82 Loss: 0.054578747600317\n",
      "Epoch: 83 Loss: 0.04813075438141823\n",
      "Epoch: 84 Loss: 0.1145855262875557\n",
      "Epoch: 85 Loss: 0.12799334526062012\n",
      "Epoch: 86 Loss: 0.06712830066680908\n",
      "Epoch: 87 Loss: 0.17009802162647247\n",
      "Epoch: 88 Loss: 0.10139558464288712\n",
      "Epoch: 89 Loss: 0.060294702649116516\n",
      "Epoch: 90 Loss: 0.32788270711898804\n",
      "Epoch: 91 Loss: 0.0472918301820755\n",
      "Epoch: 92 Loss: 0.053337667137384415\n",
      "Epoch: 93 Loss: 0.09717102348804474\n",
      "Epoch: 94 Loss: 0.031188908964395523\n",
      "Epoch: 95 Loss: 0.08561788499355316\n",
      "Epoch: 96 Loss: 0.03762339428067207\n",
      "Epoch: 97 Loss: 0.01591484062373638\n",
      "Epoch: 98 Loss: 0.06523597985506058\n",
      "Epoch: 99 Loss: 0.06386066228151321\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size = 128, shuffle = True)    # (128, 3, 32, 32)\n",
    "\n",
    "print(train_loader)\n",
    "\n",
    "model = nn.Sequential(\n",
    "            nn.Linear(3072, 512),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512, 2),\n",
    "            nn.LogSoftmax(dim = 1))\n",
    "\n",
    "learning_rate = 1e-2\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr = learning_rate)\n",
    "\n",
    "loss_fn = nn.NLLLoss()\n",
    "\n",
    "n_epochs = 100\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for imgs, labels in train_loader:\n",
    "        batch_size = imgs.shape[0]\n",
    "        outputs = model(imgs.view(batch_size, -1))\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "                       \n",
    "    print(f\"Epoch: {epoch} Loss: {float(loss)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "78700dc1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.818\n"
     ]
    }
   ],
   "source": [
    "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size = 128, shuffle = True)    # (128, 3, 32, 32)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in val_loader:\n",
    "        batch_size = imgs.shape[0]\n",
    "        outputs = model(imgs.view(batch_size, -1))\n",
    "        \n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "        total += labels.shape[0]\n",
    "        correct += int((predicted == labels).sum())\n",
    "\n",
    "print(f\"Accuracy : {float(correct / total)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a29147ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1574402, [1572864, 512, 1024, 2])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numel_list = [p.numel() for p in model.parameters() if p.requires_grad == True]\n",
    "sum(numel_list), numel_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
